{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "## Lecture 10 assessed exercises\n",
    "\n",
    "# Packages\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this set of exercises we are going to use the prostate dataset and the diamonds dataset. Testing your functions with two different datasets should catch any error  related to leaving the DataFrame names inside your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/joshward/Desktop/Fin. Math/Y4S1/Data Programming/'\n",
    "\n",
    "prostate = pd.read_csv('http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data',index_col='Unnamed: 0',sep='\\t')\n",
    "diamonds = pd.read_csv(path+'diamonds.csv')\n",
    "# Remove cathegorical data and take subset of diamonds dataset\n",
    "dataA = prostate.drop('train',axis=1)\n",
    "dataB = dataQ1b = diamonds.drop(['cut','color','clarity'],axis=1).iloc[:100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's fit some regression models and create a stepwise AIC function\n",
    " As we learnt in lectures to fit a regression model, we need to create a DataFrame X \n",
    " and Series y. X should contain the standardised version of all of the explanatory/\n",
    " exogenous variables and y should contain the standardised version of the response/\n",
    " endogenous variable. To fit the intercept, X must have an additional column of ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Write a function to create X and y for a given DataFrame df. \n",
    "The function inputs are;\n",
    "- the DataFrame df \n",
    "- the label of the response/endogenous variable \n",
    "- res_col\n",
    "\n",
    "The function should return two objects, X and y (in that order), **where X and why are both standardised  and the column of ones is the first column of X.** (You may assume that none of the variables are categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise1(df,res_col):\n",
    "    X = df.drop([res_col],axis=1)\n",
    "    X = (X - X.mean(axis=0)) / X.std()\n",
    "    X.insert(0,'intercept',1)\n",
    "    y = df[res_col]\n",
    "    y = (y - y.mean(axis=0)) / y.std()\n",
    "    return X,y\n",
    "    \n",
    "# Suggested tests\n",
    "XA, yA = exercise1(dataA,'lpsa') \n",
    "XB, yB = exercise1(dataB,'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to check to ensure code is working correctly\n",
    " - XA and XB have the same number of rows and columns as dataA and dataB, respectively\n",
    " - the first column of XA and XB is entirely ones\n",
    " - yA and yB are Series with the same number of rows as dataA and dataB, respectively\n",
    " - the mean of each variable in XA, XB, yA and yB (apart from the intercept column) is close to zero (~10^(-16))\n",
    " - the std of each variable in XA, XB, yA and yB (apart from the intercept column) is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Write a function that takes X and y as inputs and fits a linear regression model.\n",
    "- The function should return the rsquared value rounded to 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise2(X,y):\n",
    "    mod = sm.OLS(y,X)\n",
    "    res = mod.fit()\n",
    "    return round(res.rsquared,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested tests\n",
    "Remember we can unpack a tuple to use as a set of inputs to a function. Here we unpack the tuple (X,y) returned by exercise1 to use as an input for exercise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6634\n"
     ]
    }
   ],
   "source": [
    "print(exercise2(*exercise1(dataA,'lpsa')))\n",
    "# Should give 0.6634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9426\n"
     ]
    }
   ],
   "source": [
    "print(exercise2(*exercise1(dataB,'price')))\n",
    "# Should give 0.9426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC is the Akaike information criterion. It's designed to penalise models with  lots of explanatory variables so that we pick models which fit the data well but aren't too complicated. In general, if you have two models fitted to the same data,  the model with the lowest AIC is preferable. The AIC is given as part of the model  summary with OLS \n",
    "\n",
    "### The steps to run a forward selection AIC regression are: \n",
    "- Run a linear regression with just the intercept column. Get the AIC.\n",
    "- Add in the explanatory variables individually, run a linear regression for each one and determine how much they decreases the AIC\n",
    "- Find the variable with the biggest decrease in AIC and include it in your linear model\n",
    "- Repeat step 2-3 with this new linear model and remaining explanatory variables\n",
    "- Repeat this process until none of the remaining explanatory variables reduce the AIC\n",
    "\n",
    "### The explanatory variables that have been included up to the stopping point are considered the variables that produce a good fit without overcomplicating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Write a function that performs the AIC algorithm for a given DataFrame X and Series y. The function should return the names of the columns used for the model that gives the lowest AIC. This question is worth 2 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise3(X,y):\n",
    "    X_new = X.iloc[:,0]\n",
    "    AIC_intercept = sm.OLS(y,X.iloc[:,0]).fit().aic\n",
    "    X = X.drop(columns=['intercept'])\n",
    "    x1,x2 = 0,1\n",
    "    while x1 < x2:\n",
    "        AIC = []\n",
    "        for i in list(X.columns):\n",
    "            X_loop = pd.concat([X_new, X.loc[:,i]], axis=1)\n",
    "            AIC.append(sm.OLS(y,X_loop).fit().aic)\n",
    "        if min(AIC) < AIC_intercept:\n",
    "            AIC_intercept = min(AIC)\n",
    "            col = X.iloc[:,np.argmin(AIC)].name\n",
    "            X_new = pd.concat([X_new, X.loc[:,col]],axis=1)\n",
    "            X = X.drop(columns=[col])\n",
    "        else:\n",
    "            x1 = x2\n",
    "    return list(X_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'lcavol', 'lweight', 'svi', 'lbph', 'age']\n"
     ]
    }
   ],
   "source": [
    "print(exercise3(*exercise1(dataA,'lpsa')))\n",
    "# Should give ['intercept', 'lcavol', 'lweight', 'svi', 'lbph', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'carat', 'z', 'x', 'y', 'table']\n"
     ]
    }
   ],
   "source": [
    "print(exercise3(*exercise1(dataB,'price')))\n",
    "# Should give ['intercept', 'carat', 'z', 'x', 'y', 'table']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
