{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 11 - Assessed exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these assessed exercises we're going to perform some model comparison on a  handwriting recognition multi-class data set. We're going to divide it up into training, validation and test sets. We're going to run different parameter  values on the training and validation sets to determine the optimal parameters Then we're going to run the optimal values on the test set to compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models we're going to use are:\n",
    " - Random forests\n",
    " - k nearest neighbours\n",
    " - Multi-layer perceptron (a type of neural network)\n",
    "\n",
    "You can load in these classifiers with the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other packages we may need\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the digits data with \n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that each sklearn data set comes with a target object (the response) and a data object (the explanatory variables). \n",
    "\n",
    "These data concern handwriting recognition so the response is a digit (0 to 9) and the explanatory variables\n",
    "are levels of grey on an 8 by 8 grid.\n",
    "You can get a plot of any row (a handwriting sample) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.05, '4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "choose_row = 100\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[choose_row]) \n",
    "plt.title(digits.target[choose_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where here I've made the title the digit it's supposed to represent (4). Looking at the plot you should see that it resembles a 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the value of choose_row to see different digits and how they've been drawn. Note that this data set has an extra object 'images' that contains the 8 by 8 matrices containing the pixel intensities, we will ignore this object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "choose_row = 50\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[choose_row]) \n",
    "plt.title(digits.target[choose_row])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function for creating training, validation and test sets for a given\n",
    "matrix of observations X and vector of responses y. The function also needs a\n",
    "seed value so that it can reproduce the same outputs. The data is split 50%,\n",
    "25%, 25% between training, validation and test, respectively. We will use this\n",
    "function when creating our training, validation and test sets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_sets(X,y,s):\n",
    "    npr.seed(s)\n",
    "    inds= npr.permutation(range(len(y)))\n",
    "    n_train = int(len(y)/2)\n",
    "    n_val =  int(3*len(y)/4)\n",
    "    X_train = X[inds[:n_train],:]\n",
    "    y_train = y[inds[:n_train]]\n",
    "    X_val = X[inds[n_train:n_val],:]\n",
    "    y_val = y[inds[n_train:n_val]]\n",
    "    X_test = X[inds[n_val:],:]\n",
    "    y_test = y[inds[n_val:]]\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 Write a function that runs each of the three classifiers with their default  parameter values. The function inputs are the training and test sets X_train, X_test, y_train, y_test and a seed value s. The seed value should be used as the random_state argument in RandomForestClassifier and MLPClassifier. The function should return a dict with keys 'knn', 'rf' and 'svm'. The values should be the misclassification rate for each classifier (rounded to 3dp). Remember that  there are more than two categories, so your mis-classification table will have more rows and columns to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise1(X_train,X_test,y_train,y_test,s):\n",
    "\n",
    "    def misclassification_cross(y_test,test_pred):\n",
    "        cross = pd.crosstab(test_pred,y_test).to_numpy()\n",
    "        return (cross.sum() - (np.diagonal(cross)).sum())/(cross).sum()\n",
    "                    \n",
    "    rf = RandomForestClassifier(random_state=s)\n",
    "    rf_fit = rf.fit(X_train,y_train)\n",
    "    rf_test_pred = rf_fit.predict(X_test)    \n",
    "    rf_error_rate = misclassification_cross(y_test,rf_test_pred)\n",
    "    \n",
    "    kn = KNeighborsClassifier()\n",
    "    kn_fit = kn.fit(X_train,y_train)\n",
    "    kn_test_pred = kn_fit.predict(X_test)\n",
    "    kn_error_rate = misclassification_cross(y_test,kn_test_pred)\n",
    "    \n",
    "    mlp = MLPClassifier(random_state=s)\n",
    "    mlp_fit = mlp.fit(X_train,y_train)\n",
    "    mlp_test_pred = mlp_fit.predict(X_test)\n",
    "    mlp_error_rate = misclassification_cross(y_test,mlp_test_pred)\n",
    "\n",
    "    \n",
    "    return {'knn':round(kn_error_rate,3),'mlp':round(mlp_error_rate,3),'rf':round(rf_error_rate,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn': 0.024, 'mlp': 0.031, 'rf': 0.076}\n"
     ]
    }
   ],
   "source": [
    "# Suggested test\n",
    "X1 = digits.data\n",
    "y1 = digits.target\n",
    "# We can use underscores to ignore the outputs of train_val_test_sets that we don't need\n",
    "[X_train1, _, X_test1, y_train1, _, y_test1] = train_val_test_sets(X1,y1,99)\n",
    "print(exercise1(X_train1,X_test1,y_train1,y_test1,123))\n",
    "# This should return \n",
    "# {'knn': 0.024, 'mlp': 0.031, 'rf': 0.076}\n",
    "# You can ignore the warning messages for now\n",
    "# Again, this should return the same answer every time you run it with the inputs\n",
    "# X2, y2 and 99. If you use a subset of X2 and y2, or change the seed value you \n",
    "# should expect these values to change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the above models has key parameters which we might like to estimate. For \n",
    "example, we might want to estimate the 'best' number of neighbours to use in kNN\n",
    "To do this, we fit kNN with different values of k to the training set and evaluate\n",
    "the performance of each model using the validation set. The k value that gives the\n",
    "best performance on the validation data is chosen as the best model. We then \n",
    "evaluate the performance of this model on data the classifier hasn't seen before,\n",
    "the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Write a function that determines the 'best' number of neighbours k to use in  the kNN classifier and evaluates the performance of the best model on the test set. The function inputs are the training, validation and test sets and a list of  values of k to try. The function should return a dict with the best k value (key:  'k') and the misclassification rate for the test set (key: 'MR') (rounded to 3dp). Ensure that you use these exact keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise2(X_train,X_val,X_test,y_train,y_val,y_test,kvals):\n",
    "    \n",
    "    def misclassification_cross(y_test,test_pred):\n",
    "        cross = pd.crosstab(test_pred,y_test).to_numpy()\n",
    "        return (cross.sum() - (np.diagonal(cross)).sum())/(cross).sum()\n",
    "    \n",
    "    misclassification_rate = []\n",
    "    for i in kvals:\n",
    "            kn = KNeighborsClassifier(i)\n",
    "            kn_fit = kn.fit(X_train,y_train)\n",
    "            kn_test_pred = kn_fit.predict(X_val)\n",
    "            kn_error_rate = misclassification_cross(y_val,kn_test_pred)\n",
    "            misclassification_rate.append(kn_error_rate)\n",
    "            \n",
    "    kn = KNeighborsClassifier(kvals[np.argmin(misclassification_rate)])\n",
    "    kn_fit = kn.fit(X_train,y_train)\n",
    "    kn_test_pred = kn_fit.predict(X_test)\n",
    "    kn_error_rate = misclassification_cross(y_test,kn_test_pred)\n",
    "            \n",
    "    return {'k':kvals[np.argmin(misclassification_rate)],'MR':round(kn_error_rate,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 2, 'MR': 0.031}\n"
     ]
    }
   ],
   "source": [
    "# Suggestes test\n",
    "print(exercise2(*train_val_test_sets(X1,y1,199),range(1,22)))\n",
    "# This should return {'k': 2, 'MR': 0.031}\n",
    "# If you change the seed value for creating your training, validation and test sets\n",
    "# you can expect to get different values for k and the missclassification rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Write a function that determines the 'best' number of trees (n_estimators) to use in the random forest classifier and evaluates the performance of the best model on the test set. The function inputs are the training, validation and test sets, a list of values of n_estimators to try and a seed value s to use as the random_stat for the classifier. The function should return a dict with the best number of trees (key: 'Trees') and the misclassification rate for the test set (key: 'MR') (rounded to 3dp) Ensure that you use these exact keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise3(X_train,X_val,X_test,y_train,y_val,y_test,tree_vals,s):\n",
    "    \n",
    "    def misclassification_cross(y_test,test_pred):\n",
    "        cross = pd.crosstab(test_pred,y_test).to_numpy()\n",
    "        return (cross.sum() - (np.diagonal(cross)).sum())/(cross).sum()\n",
    "    \n",
    "    misclassification_rate = []\n",
    "    for i in tree_vals:\n",
    "            rf = RandomForestClassifier(n_estimators=i,random_state=s)\n",
    "            rf_fit = rf.fit(X_train,y_train)\n",
    "            rf_test_pred = rf_fit.predict(X_val)\n",
    "            rf_error_rate = misclassification_cross(y_val,rf_test_pred)\n",
    "            misclassification_rate.append(rf_error_rate)\n",
    "            \n",
    "    rf = RandomForestClassifier(n_estimators=tree_vals[np.argmin(misclassification_rate)],random_state=s)\n",
    "    rf_fit = rf.fit(X_train,y_train)\n",
    "    rf_test_pred = rf_fit.predict(X_test)\n",
    "    rf_error_rate = misclassification_cross(y_test,rf_test_pred)\n",
    "        \n",
    "    return {'Trees':tree_vals[np.argmin(misclassification_rate)],'MR':round(rf_error_rate,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Trees': 55, 'MR': 0.038}\n"
     ]
    }
   ],
   "source": [
    "# Suggestes test\n",
    "print(exercise3(*train_val_test_sets(X1,y1,99),range(5,101,5),23))\n",
    "# This should return {'Trees': 55, 'MR': 0.038}\n",
    "# Again, changing the seed value for creating your training, validation and test sets\n",
    "# will change the number of trees and the missclassification rate. As will changing\n",
    "# the seed value for the random state of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 The parameter we wish to estimate for the multi-layer perceptron classifier is the number of neurons in the hidden layers of the neural network. To change this parameter include hidden_layer_sizes=num_neurons as an input to the MLPClassifier function. Write a function that determines the 'best' number of neurons in the  multi-layer perceptron classifier and evaluates the performance of the best model  on the test set. The function inputs are the training, validation and test sets,  a list of values of hidden_layer_sizes to try and a seed value s to use as the  random_state for the classifier. The function should return a dict with the best number of neurons (key: 'Neurons') and the  misclassification rate for the test  set (key: 'MR') (rounded to 3dp). Ensure that you use these exact keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise4(X_train,X_val,X_test,y_train,y_val,y_test,layer_vals,s):\n",
    "    \n",
    "    def misclassification_cross(y_test,test_pred):\n",
    "        cross = pd.crosstab(test_pred,y_test).to_numpy()\n",
    "        return (cross.sum() - (np.diagonal(cross)).sum())/(cross).sum()\n",
    "    \n",
    "    misclassification_rate = []\n",
    "    for i in layer_vals:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=i,random_state=s)\n",
    "            mlp_fit = mlp.fit(X_train,y_train)\n",
    "            mlp_test_pred = mlp_fit.predict(X_val)\n",
    "            mlp_error_rate = misclassification_cross(y_val,mlp_test_pred)\n",
    "            misclassification_rate.append(mlp_error_rate)\n",
    "            \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=layer_vals[np.argmin(misclassification_rate)],random_state=s)\n",
    "    mlp_fit = mlp.fit(X_train,y_train)\n",
    "    mlp_test_pred = mlp_fit.predict(X_test)\n",
    "    mlp_error_rate = misclassification_cross(y_test,mlp_test_pred)\n",
    "            \n",
    "    return {'Neurons':layer_vals[np.argmin(misclassification_rate)],'MR':round(mlp_error_rate,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Neurons': 550, 'MR': 0.033}\n"
     ]
    }
   ],
   "source": [
    "# Suggested test\n",
    "print(exercise4(*train_val_test_sets(X1,y1,175),range(50,1551,100),45))\n",
    "# This should return {'Neurons': 550, 'MR': 0.033}\n",
    "# As before, changing either seed value will change the number of neurons and the \n",
    "# missclassification rate.\n",
    "# Note that this function will take ~20s to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
